[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Théorie générale des tests statistiques",
    "section": "",
    "text": "1.1 Concepts fondamentaux\nLe test d’hypothèse est un concept fondamental dans le monde scientifique. Un test d’hypothèse a pour but de présenter une règle de décision, établie à l’aide de résultats d’échantillon, permettant de d’effectuer un choix entre deux hypothèses statistiques.\nQu’est-ce qu’une hypothèse statistique ? C’est une affirmation a priori sur une ou plusieurs caractéristiques d’une population telles que la valeur de paramètres, la distribution des observations.\nIl existe deux types d’hypothèses :\nLes erreurs de Type I et de Type II, qu’est-ce ?\nLa puissance d’un test statistique, c’est la probabilité de rejeter H₀ lorsque H₀ est fausse. Elle se calcul ainsi : puissance = 1 - β",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Théorie générale des tests statistiques</span>"
    ]
  },
  {
    "objectID": "intro.html#concepts-fondamentaux",
    "href": "intro.html#concepts-fondamentaux",
    "title": "1  Théorie générale des tests statistiques",
    "section": "",
    "text": "Hypothèse nulle (H₀) : hypothèse soumise au test statistique et considérée comme vraie pour le test, H₀ est souvent un modèle simple ou bien une valeur définie d’un paramètre. Exemple, il n’y a pas de différence entre les moyennes de mes deux groupes, H₀ : µ₁ = µ2\nHypothèse alternative (H₁) : hypothèse différente de H₀, communément son opposé. Exemple H₁ : µ₁ ≠ µ2\n\n\n\nα l’erreur de Type I (ou risque de première espèce) : c’est la probabilité de rejeter H₀ alors que H₀ est vraie. Dit autrement, c’est le risque de conclure à tort, via les résultats obtenus, sur une différence réelle alors qu’elle est due au hasard. Exemple : un joueur joue à la roulette, il lance la roue 6 fois, il voit sortir 4 numéros rouges et 2 numéros noirs. Il en conclu qu’il y a deux fois plus de numéros rouges que de noirs.\n\n\n\n\n\n\n\n\nExemple : Jeu de la Roulette\n\n\n\n\n\nβ l’erreur de Type II (ou risque de deuxième espèce) : c’est la probabilité de ne pas rejeter H₀ alors que H₀ est fausse. En autres, c’est le risque de conclure à tort qu’il n’y a pas de différence alors qu’il y a une différence réelle.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Théorie générale des tests statistiques</span>"
    ]
  },
  {
    "objectID": "intro.html#test-de-student-ou-t-test",
    "href": "intro.html#test-de-student-ou-t-test",
    "title": "1  Théorie générale des tests statistiques",
    "section": "1.2 Test de Student (ou t test)",
    "text": "1.2 Test de Student (ou t test)\nLe test de Student permet une comparaison simple mais importante, celle des moyennes entre deux groupes. La statistique de test est définie ainsi\n\\[\nt = c \\, \\frac{\\bar{m}_1 - \\bar{m}_2}{s}\n\\]\nOù \\(\\bar{m}_1\\) et \\(\\bar{m}_2\\) sont les moyennes respectives des deux groupes, \\(c\\) est une constante dépendante de la taille d’échantillon, \\(s^{2}\\) est l’estimateur sans biais de la variance globale. \\[\n\\bar{m}_1 = \\frac{1}{n_1} \\sum_{i=1}^{n_1} x_{1,i}\n\\qquad\n\\bar{m}_2 = \\frac{1}{n_2} \\sum_{i=1}^{n_2} x_{2,i}\n\\]\n\\(s_1^2\\) et \\(s_2^2\\) sont les estimateurs sans biais de la variance intra-groupe.\n\\[\ns_1^2 = \\frac{1}{n_1 - 1} \\sum_{i=1}^{n_1} (x_{1,i} - \\bar{m}_1)^2\n\\qquad\ns_2^2 = \\frac{1}{n_2 - 1} \\sum_{i=1}^{n_2} (x_{2,i} - \\bar{m}_2)^2\n\\]\n\\[\ns =\n\\sqrt{\n\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}\n     {n_1 + n_2 - 2}\n}\n\\]\n\\[\nc = \\sqrt{\\frac{n_1 n_2}{n_1 + n_2}}\n\\]\n\n\n\n\n1.2.1 Test de Student à deux échantillons indépendants\nCompare les moyennes de deux groupes indépendants : trt2 (n=10) et crtl (n=10).\n\n\n\n\n\n\n\nExemple de données de deux groupes\n\n\n\n\n\ntt &lt;- with(exemple_data,\n          t.test(weight[group ==\"ctrl\"],\n                 weight[group ==\"trt2\"],\n                 var.equal = TRUE))\ntt\n\n\n    Two Sample t-test\n\ndata:  weight[group == \"ctrl\"] and weight[group == \"trt2\"]\nt = -2.134, df = 18, p-value = 0.04685\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.980338117 -0.007661883\nsample estimates:\nmean of x mean of y \n    5.032     5.526 \n\n\nOn observe une différence entre mes deux groupes de faible échantillon, que ce passerait-il si on augmente artificiellement la taille d’échantillon en dupliquant les données ? Je conserve le même groupe\n\n\n\n\n\n\n\n\n\n\ndata_k &lt;- exemple_data %&gt;%\n  slice(rep(row_number(), times = 10))\n\ntt_10 &lt;- with(\n  data_k,\n  t.test(\n    weight[group == \"ctrl\"],\n    weight[group == \"trt2\"],\n    var.equal = TRUE\n  )\n)\ntt_10\n\n\n    Two Sample t-test\n\ndata:  weight[group == \"ctrl\"] and weight[group == \"trt2\"]\nt = -7.0777, df = 198, p-value = 2.483e-11\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.6316394 -0.3563606\nsample estimates:\nmean of x mean of y \n    5.032     5.526 \n\n\nDans cet exemple j’ai dupliqué dix fois le jeu de données, on peut voir que les moyennes sont identiques mais que la pvalue associée est bien plus basse :\n\nLa puissance statistique associée au test de Student est dépendante de la taille d’échantillon. Plus le nombre d’observations est élevé, plus les résultats seront significatifs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Théorie générale des tests statistiques</span>"
    ]
  },
  {
    "objectID": "intro.html#test-de-proportion",
    "href": "intro.html#test-de-proportion",
    "title": "1  Théorie générale des tests statistiques",
    "section": "1.3 Test de proportion",
    "text": "1.3 Test de proportion\nTeste si une proportion observée diffère d’une proportion théorique.\n\n# Exemple: 55 succès sur 100 essais\n# H₀: p = 0.5 vs H₁: p ≠ 0.5\nresultat_prop &lt;- prop.test(x = 55, n = 100, p = 0.5)\nprint(resultat_prop)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  55 out of 100, null probability 0.5\nX-squared = 0.81, df = 1, p-value = 0.3681\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.4475426 0.6485719\nsample estimates:\n   p \n0.55 \n\n# Test de comparaison de deux proportions\n# Groupe 1: 45/100, Groupe 2: 60/100\nresultat_prop2 &lt;- prop.test(x = c(45, 60), n = c(100, 100))\nprint(resultat_prop2)\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  c(45, 60) out of c(100, 100)\nX-squared = 3.9298, df = 1, p-value = 0.04744\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.296847038 -0.003152962\nsample estimates:\nprop 1 prop 2 \n  0.45   0.60 \n\n# Visualisation\nprop_data &lt;- data.frame(\n  groupe = c(\"Groupe 1\", \"Groupe 2\"),\n  proportion = c(45/100, 60/100),\n  n = c(100, 100)\n)\n\nggplot(prop_data, aes(x = groupe, y = proportion, fill = groupe)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  geom_errorbar(aes(ymin = proportion - 1.96*sqrt(proportion*(1-proportion)/n),\n                    ymax = proportion + 1.96*sqrt(proportion*(1-proportion)/n)),\n                width = 0.2) +\n  labs(title = \"Comparaison de proportions\",\n       subtitle = paste(\"p-value =\", round(resultat_prop2$p.value, 4)),\n       y = \"Proportion\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Théorie générale des tests statistiques</span>"
    ]
  },
  {
    "objectID": "intro.html#test-de-wilcoxon",
    "href": "intro.html#test-de-wilcoxon",
    "title": "1  Théorie générale des tests statistiques",
    "section": "1.4 Test de Wilcoxon",
    "text": "1.4 Test de Wilcoxon\nTest non-paramétrique alternatif au test t (ne suppose pas la normalité).\n\n1.4.1 Test de Mann-Whitney (Wilcoxon pour deux échantillons indépendants)\n\ngroupe_X &lt;- rexp(30, rate = 0.1)\ngroupe_Y &lt;- rexp(30, rate = 0.08)\n\nresultat_mw &lt;- wilcox.test(groupe_X, groupe_Y)\nprint(resultat_mw)\n\n\n    Wilcoxon rank sum exact test\n\ndata:  groupe_X and groupe_Y\nW = 348, p-value = 0.1342\nalternative hypothesis: true location shift is not equal to 0\n\n# Visualisation\ndonnees_mw &lt;- data.frame(\n  valeur = c(groupe_X, groupe_Y),\n  groupe = rep(c(\"Groupe X\", \"Groupe Y\"), each = 30)\n)\n\nggplot(donnees_mw, aes(x = groupe, y = valeur, fill = groupe)) +\n  geom_violin(alpha = 0.7) +\n  geom_boxplot(width = 0.2, fill = \"white\") +\n  labs(title = \"Test de Mann-Whitney\",\n       subtitle = paste(\"p-value =\", round(resultat_mw$p.value, 4)),\n       y = \"Valeurs\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Théorie générale des tests statistiques</span>"
    ]
  },
  {
    "objectID": "intro.html#family-wise-error-rate-fwer",
    "href": "intro.html#family-wise-error-rate-fwer",
    "title": "1  Théorie générale des tests statistiques",
    "section": "2.1 Family-Wise Error Rate (FWER)",
    "text": "2.1 Family-Wise Error Rate (FWER)\nProbabilité de faire au moins une erreur de type I parmi tous les tests.\nFWER = P(au moins un faux positif)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Théorie générale des tests statistiques</span>"
    ]
  },
  {
    "objectID": "intro.html#false-discovery-rate-fdr",
    "href": "intro.html#false-discovery-rate-fdr",
    "title": "1  Théorie générale des tests statistiques",
    "section": "2.2 False Discovery Rate (FDR)",
    "text": "2.2 False Discovery Rate (FDR)\nProportion attendue de faux positifs parmi les découvertes significatives.\nFDR = E(V/R) où V = nombre de faux positifs, R = nombre de rejets",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Théorie générale des tests statistiques</span>"
    ]
  },
  {
    "objectID": "intro.html#corrections-pour-tests-multiples",
    "href": "intro.html#corrections-pour-tests-multiples",
    "title": "1  Théorie générale des tests statistiques",
    "section": "2.3 Corrections pour tests multiples",
    "text": "2.3 Corrections pour tests multiples\n\n# Générer des p-values de test\nset.seed(123)\nn_tests &lt;- 100\n# 90 vrais H₀ (non significatifs) et 10 vrais H₁ (significatifs)\np_vals &lt;- c(\n  runif(90, 0.05, 1),  # vrais négatifs\n  runif(10, 0, 0.01)   # vrais positifs\n)\np_vals &lt;- sample(p_vals)  # mélanger\n\n\n2.3.1 Correction de Bonferroni\nContrôle strictement le FWER en divisant α par le nombre de tests.\nα_corrigé = α / m où m = nombre de tests\n\nalpha &lt;- 0.05\nbonf_threshold &lt;- alpha / n_tests\n\ncat(\"Seuil de Bonferroni:\", bonf_threshold, \"\\n\")\n\nSeuil de Bonferroni: 5e-04 \n\ncat(\"Tests significatifs (non corrigé):\", sum(p_vals &lt; alpha), \"\\n\")\n\nTests significatifs (non corrigé): 10 \n\ncat(\"Tests significatifs (Bonferroni):\", sum(p_vals &lt; bonf_threshold), \"\\n\")\n\nTests significatifs (Bonferroni): 0 \n\n# Avec p.adjust\np_bonf &lt;- p.adjust(p_vals, method = \"bonferroni\")\ncat(\"Tests significatifs (p.adjust):\", sum(p_bonf &lt; alpha), \"\\n\")\n\nTests significatifs (p.adjust): 0 \n\n\n\n\n2.3.2 Correction de Holm (Bonferroni séquentielle)\nVersion moins conservative de Bonferroni.\n\np_holm &lt;- p.adjust(p_vals, method = \"holm\")\n\ncat(\"Tests significatifs (Holm):\", sum(p_holm &lt; alpha), \"\\n\")\n\nTests significatifs (Holm): 0 \n\n\n\n\n2.3.3 False Discovery Rate (Benjamini-Hochberg)\nContrôle le FDR au lieu du FWER, plus puissant pour les tests multiples.\n\np_fdr &lt;- p.adjust(p_vals, method = \"BH\")\n\ncat(\"Tests significatifs (FDR/BH):\", sum(p_fdr &lt; alpha), \"\\n\")\n\nTests significatifs (FDR/BH): 0 \n\n\n\n\n2.3.4 Comparaison des méthodes\n\n# Créer un tableau comparatif\ncomparaison &lt;- data.frame(\n  p_value = p_vals,\n  rang = rank(p_vals),\n  non_corrige = p_vals &lt; alpha,\n  bonferroni = p_bonf &lt; alpha,\n  holm = p_holm &lt; alpha,\n  BH_FDR = p_fdr &lt; alpha\n)\n\n# Résumé\nresume &lt;- data.frame(\n  Methode = c(\"Non corrigé\", \"Bonferroni\", \"Holm\", \"BH (FDR)\"),\n  Significatifs = c(\n    sum(comparaison$non_corrige),\n    sum(comparaison$bonferroni),\n    sum(comparaison$holm),\n    sum(comparaison$BH_FDR)\n  )\n)\n\nprint(resume)\n\n      Methode Significatifs\n1 Non corrigé            10\n2  Bonferroni             0\n3        Holm             0\n4    BH (FDR)             0\n\n# Visualisation\ncomparaison_long &lt;- comparaison %&gt;%\n  select(rang, non_corrige, bonferroni, holm, BH_FDR) %&gt;%\n  pivot_longer(-rang, names_to = \"methode\", values_to = \"significatif\") %&gt;%\n  mutate(methode = factor(methode, \n                          levels = c(\"non_corrige\", \"bonferroni\", \"holm\", \"BH_FDR\"),\n                          labels = c(\"Non corrigé\", \"Bonferroni\", \"Holm\", \"BH (FDR)\")))\n\nggplot(comparaison_long, aes(x = rang, y = methode, fill = significatif)) +\n  geom_tile() +\n  scale_fill_manual(values = c(\"white\", \"darkgreen\"), \n                    labels = c(\"Non significatif\", \"Significatif\")) +\n  labs(title = \"Comparaison des méthodes de correction\",\n       x = \"Rang de la p-value (1 = plus petite)\",\n       y = \"Méthode\",\n       fill = \"\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n2.3.5 Visualisation des seuils de décision\n\n# Créer un dataframe pour la visualisation\ndf_viz &lt;- data.frame(\n  rang = 1:n_tests,\n  p_value = sort(p_vals)\n) %&gt;%\n  mutate(\n    seuil_standard = alpha,\n    seuil_bonferroni = alpha / n_tests,\n    seuil_BH = (rang / n_tests) * alpha\n  )\n\nggplot(df_viz, aes(x = rang)) +\n  geom_point(aes(y = p_value), alpha = 0.6) +\n  geom_line(aes(y = seuil_standard, color = \"Standard (α = 0.05)\"), \n            size = 1, linetype = \"dashed\") +\n  geom_line(aes(y = seuil_bonferroni, color = \"Bonferroni\"), \n            size = 1) +\n  geom_line(aes(y = seuil_BH, color = \"Benjamini-Hochberg\"), \n            size = 1) +\n  scale_color_manual(values = c(\"red\", \"blue\", \"green\")) +\n  labs(title = \"Seuils de décision selon les méthodes\",\n       x = \"Rang de la p-value\",\n       y = \"P-value\",\n       color = \"Méthode\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Théorie générale des tests statistiques</span>"
    ]
  },
  {
    "objectID": "intro.html#recommandations-pratiques",
    "href": "intro.html#recommandations-pratiques",
    "title": "1  Théorie générale des tests statistiques",
    "section": "2.4 Recommandations pratiques",
    "text": "2.4 Recommandations pratiques\n\n2.4.1 Choix de la méthode\n\n\n\nSituation\nMéthode recommandée\n\n\n\n\nNombre limité de tests (&lt; 10)\nBonferroni\n\n\nBesoin de contrôle strict du FWER\nBonferroni ou Holm\n\n\nGrand nombre de tests\nFDR (Benjamini-Hochberg)\n\n\nExploration de données\nFDR (Benjamini-Hochberg)\n\n\nConfirmation d’hypothèses\nBonferroni\n\n\n\n\n\n2.4.2 Code récapitulatif\n\n# Fonction pour comparer toutes les méthodes\ncomparer_corrections &lt;- function(p_values, alpha = 0.05) {\n  data.frame(\n    Methode = c(\"Non corrigé\", \"Bonferroni\", \"Holm\", \"Hochberg\", \n                \"Hommel\", \"BH (FDR)\", \"BY (FDR)\"),\n    Significatifs = c(\n      sum(p_values &lt; alpha),\n      sum(p.adjust(p_values, \"bonferroni\") &lt; alpha),\n      sum(p.adjust(p_values, \"holm\") &lt; alpha),\n      sum(p.adjust(p_values, \"hochberg\") &lt; alpha),\n      sum(p.adjust(p_values, \"hommel\") &lt; alpha),\n      sum(p.adjust(p_values, \"BH\") &lt; alpha),\n      sum(p.adjust(p_values, \"BY\") &lt; alpha)\n    )\n  )\n}\n\n# Exemple d'utilisation\ncomparer_corrections(p_vals)\n\n      Methode Significatifs\n1 Non corrigé            10\n2  Bonferroni             0\n3        Holm             0\n4    Hochberg             0\n5      Hommel             0\n6    BH (FDR)             0\n7    BY (FDR)             0",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Théorie générale des tests statistiques</span>"
    ]
  }
]